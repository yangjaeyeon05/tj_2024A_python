'''
    - 함수(function)
        - 수학 : 어떤 집합의 각 원소를 다른 어떤 집합의 유일한 원소에 대응시키는 이항 관계
        - * 프로그래밍 함수 : 어떤한 코드 집합에 매개변수(N개)를 대입하고 결과 변수(1개)를 받는 구조
    - 예시
            x = 3
    ---- ---------
    /   y = x + 4 /
    ---- ---------
            y = 7
    - (수학) 일차 함수
        x       y
        1 ----> 1
        2 ----> 4
        3 ----> 6

    - 기울기 : 기울기 정도  # y증가량/x증가량 # 두 점의 x축 증가와 y축 증가를 나눈 값
        -> 기울기 계산식 : (x , y)    (a , b) # (x -> a 증가량)  # (y -> b 증가량)
        예) (-2 , 0) (0 , 3) # 기울기 = 3 / 2 = 1.5
        예) (-3 , 1) (3 , -2)    # 기울기 = -3/6 = -0.5

    - 미분 : 미세한 부분
        - 실제 y(종속변수) , 예측 y --> 평균제곱오차 # 딥러닝 : 더 복잡하게 계산

    - 일차방적식 구하는 방법
        기울기 m , 점(지나는점) xy , ab
        1. m = y증가량/x증가량
        2. m = (y-b) / (x-a)
        3. 분모 소분 # (x-a) * m = (y-b) / (x-a) * (x-a)
        4. m(x-a) = (y-b)
        5. m(x-a) + b = y
        6. y = m(x-a) + b
            - 기울기3 , 점 : (1 , 2)
            y = 3(x-1) + 2

    - 일차 방정식 : y = ax+b
        - b(y절편) # y절편이란 : x축이 0일때 y의 값 # x절편이란? y축이 0일 때 x축의 값
        - Y = 3X -2
            X = 0 계산식 3*0 -2    Y = -2
            X = 1 계산식 3*1 -2    Y = 1

'''
# p.45
# 1. 텐서플로우 모듈 호출
import tensorflow as tf
# 2. 선형 관계를 갖는 데이터 샘플 생성 # Y = 3(기울기)X -2(Y절편)
    # 1. 텐서플로의 랜덤 숫자 생성 객체 선언   # 시드값은 아무거나     # 시드란 : 랜덤 생성할때 사용되는 제어 정수값 # tf.random.Generator.from_seed()
g = tf.random.Generator.from_seed(2020)
    # 2. 랜덤 숫자 생성 객체를 이용한 정규 분포 난수를 10개 생성해서 벡터(리스트) X에 저장한다.
    # .nomal(shape=(축1, )) # .nomal(shape=(축1,축2)) # .nomal(shape=(축1,축2,축3))
X = g.normal(shape=(10,))
Y = 3 * X -2
print(X.numpy())    # 독립변수  # 피처
# [-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918  1.082245    0.6199966  -0.44402212  1.3048344 ]
print(Y.numpy())    # 종속변수  # 타겟
# [-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024   1.2467351  -0.14001012 -3.3320663   1.9145031 ]

# 3. Loss 함수 정의 # 손실 함수(평균 제곱 오차)를 정의하는 함수
def cal_mse(X , Y , a , b):
    Y_pred = a * X + b  # Y값-종속(예축) = 계수(기울기)a * X(피처) + 상수항(Y절편)
    squared_error = (Y_pred - Y) ** 2   # 예측 Y와 실제 Y간의 차이의 제곱을 계산(오차 제곱)
    mean_squared_error = tf.reduce_mean(squared_error)  # 모든 오차 제곱의 평균을 계산하여 반환
    print(mean_squared_error)
    return mean_squared_error

# 4. 자동 미분 과정을 기록
a = tf.Variable(0.0) # 계수   # 텐서플로 변수에 0.0으로 초기화
b = tf.Variable(0.0) # Y절편  # 텐서플로 변수에 0.0으로 초기화
    # 목적 : # a와 b를 미세하게 변경하면서 반복적으로 계산하여 손실을 최소화하는 값을 찾는다.

EPOCHS = 200   # 훈련 횟수  # 에포크
for epoch in range(1 , EPOCHS+1):   # 1 ~ 200까지 (200회)
    # 200번을 반복하면서 목적 : a와 b를 미세하게 변경하면서 차이가 가장 적은 값을 찾자.
    # 4-1 mse 기록 # tf.GradientTape() as 변수 : with 안에 있는 계산식들을 모두 기록하는 역할   # mse를 tape에 기록한다.
    with tf.GradientTape() as tape:
        mse = cal_mse(X , Y , a , b)    # 위에서 정의한 손실 함수를 계산한다.
    # 4-2 기울기 계산    # tape.gradient()를 이용하여 mse에 대한 a와 b의 미분값(기울기)을 구한다.
    grad = tape.gradient(mse , {'a':a , 'b':b}) # mse에 대한 a와 b를 딕셔너리 반환한다.
    d_a , d_b = grad['a'] , grad['b']

    # 4-3 .assign_sub() 텐서플로 변수에 매개변수를 원본값에서 뺀 값으로 변수값을 수정하는 함수
    a.assign_sub(d_a * 0.05)    # 현재값에서 5% 차감   # a-= d_a*0.05
    b.assign_sub(d_b * 0.05)    # 현재값에서 0.05 차감

    # 4-4 중간 계산 확인
    if epoch % 20 == 0: # 20번마다     # epoch=반복횟수 mse=평균제곱오차 a계수 b상수항
        # print(f'{epoch} , {mse:.4f} , {a:.4f} , {b:.4f}')
        print("EPOCH %d - MES: %.4f ----- a:%.2f ----- b:%.2f"%(epoch , mse , a , b))



