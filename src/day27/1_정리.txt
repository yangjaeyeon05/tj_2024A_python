[인공지능]AI :  사람의 지능을 모방하는 넓은 범위 기술 # 머신러닝과 딥러닝을 포함
    - 다양한 문제를 해결하는 알고리즘, 규칙, 검색방식, 추론 등등을 학습할 수 있도록 만든 환경

[머신러닝] : 데이터를 통해 패턴을 학습하여 예측하는 AI의 하위 분야
    - Scikit-learn 라이브러리

[딥러닝] : 신경망을 이용해 복잡한 데이터를 학습하는 머신러닝의 하위 분야
    - TensorFlow(Keras) , PyTorch 라이브러리

인공지능 > 머신러닝 > 딥러닝

[텐서플로]
    1. 구글이 개발한 오픈소스 머신러닝 및 딥러닝 프레임워크
    2. 특히 딥러닝 연구 및 실무 환경에서 주로 사용된다.

[하이퍼파라미터]
    - 파라미터/매개변수 : 함수에 들어가는 인자값을 대입하는 변수
    - 개발자가 딥러닝 모델의 학습 과정에서 직접 설정해야하는 값 / 설정 값
    - 튜닝 : 최적 값을 찾는 과정을 하이퍼파라미터 튜닝 # 다양한 조합의 하이퍼파라미터 실험하고 성능을 평가하여 최적의 조합 찾기
        # 목적 : 어떠한 값을 설정하느냐에 따라 모델의 성능 및 결과가 달라지기 때문에 매우 중요하다.
    - 종류 : 1. 학습률 2. 에포크 3. 배치크기 4. 모델구조 5. 정규화방법 6. 옵티마이저 등등

[과소적합 vs 과대적합]
    - 과소적합
        - 모델이 너무 단순함 # 데이터 부족 # 너무 적은 수의 매개변수 # 낮은 차원의 모델
    - 과대적합
        - 모델이 너무 복잡함 # 흔련용 데이터 부족 # 너무 많은 매개변수 # 너무 많은 차원

[에포크]
    - 훈련 데이터셋이 모델을 통해 한번 완전히 학습한 횟수
    - 에포크 수는 모델의 성능에 중요한 영향을 미치고 적절한 수를 선택해야 한다.
        # 너무 적으면 과소적합이 될 수 있고 너무 많으면 과대적합이 될 수 있다.

[손실함수]
    - 모델의 예측과 실제 간의 차이를 측정(오차)하여 성능을 평가하고, 최적화 과정에서 가중치를 조정하는 기준을 제공한다.
    - 다양한 종류의 손실 함수가 존재하며, 문제의 유형에 맞게 적절한 함수를 선택하는 것이 중요하다.
        # 손실 함수는 문제의 특성에 따라 다르게 선택한다. 주로 회귀는 MSE, MAE 사용하고, 이진/다중 분류는 엔트로피를 사용한다.

[경사하강법]
    - 손실 함수를 최소화하여 모델의 가중치를 최적화하는 알고리즘이다.
    - 목표 : 손실 함수의 값을 최소화하는 가중치를 찾는 것이 목표이다. # 수학적 개념인 미분이 사용된다.
    - 기울기(그래디언트) : 손실 함수의 기울기는 현재 위치에서 함수의 증가율이다.
    - 학습률 : 기울기에 곱해져 가중치를 수정한 크기를 결정한다.
        # 학습률이 너무 크면 최적점에 도달하지 못하고 너무 작으면 특정 최적점에 빠질 수 있다. # 적절한 학습률이 필요하다.

[옵티마이저]
    - 경사하강법과 같은 방법을 사용하여 모델의 성능을 개선한다.
    - 손실 함수의 값을 최소화하기 위해 매개변수를 조정하는 알고리즘
    - 실제값과 예측값 차이(손실함수)를 최소화하는 가중치를 찾는 과정
    - 종류
        1. SGD : 매 반복마다 (무작위샘플) 이용한 가중치를 업데이트하는 구조
        2. *Adam : 가장 많이 사용되는 옵티마이저 , 기울기의 1차 평균과 2차 분산을 이용한 학습 속도 조절 # 학습률이 자동 조정된다.


[딥러닝 프로세스]
    1. 데이터 로드 -> 2. 데이터 전처리 -> 3. 데이터 분할 -> 4. 모델 생성 & 컴파일 -> 5. 훈련 -> 6. 검증 -> 7. 예측
                                                                <------- 튜닝 ------ 6번에서 4번으로 다시 돌아감

[모델]
    1. Sequential Api 순차적인 구조 모델
    2. Functional Api 복잡한 구조 모델

[노드(뉴런)]
    - 인공신경만에서 정보를 처리하고 전달되는 가장 기본적인 단위(변수처럼 각 층마다 정보를 가지고 있고 계산 받은 것을 저장하고 전달해주는 가장 기본적인 단위)
    - 사람의 뇌의 신경세포(뉴런)를 모델로 해서 만들어졌다. 노드를 뉴런이라고도 한다.
    - 역할 : 입력값 , 계산결과 , 층 간의 전달

[Dense 레이어]
    - 인공신경망에서 가장 기본적인 레이어(층)
    - Dense 레이어에는 각 노드(뉴런)가 이전 레이어의 모든 노드와 연결된 상태
    - 완전 연결층
        입력층 ---> 은닉층1 ---> 은닉층2 ---> 은닉층n ---> 출력층
    1. 입력층 : 1차원 벡터 데이터(Flatten 패턴)만 입력받을 수 있는 층/레이어
    2. 은닉층 : 입력층과 출력층 사이에 위치한 층/레이어
        - 입력 데이터에서 복잡한 패턴을 학습하는 공간
        - 데이터의 특장을 추출하고 더 정교한 정보를 만들기 위해서 사용된다.
    3. 출력층 : 최종적으로 활성화 함수에 결과가 전달되는 층/레이어
        - 이진 분류 : 활성화 함수 sigmoid
        - 다중 분류 : 활성화 함수 softmax

[활성화 함수]
    - 비선형적으로 변환해주는 함수
    - 종류 : Relu , Sigmoid , Leaky Relu , Tangent
    - 사용처 : 이미지분류 , 음성 인식 , 자연어 처리 등 복잡한 문제 해결
    - 선형 vs 비선형적
        선형적 관계 : 비례 관계
            # y = ax + b # 직선 그래프
        비선형적 관계 : 비례 관계가 아닐 때
            # 곡선 그래프

[원핫 벡터/인코딩]
    예) 결과 (0 1 2 3 4) 일때
        [1 , 0 , 0 , 0 , 0]
        [0 , 1 , 0 , 0 , 0]
    - 특정 클래스에 해당하는 위치만 1이고 나머지가 모두 0으로 설정하는 방식
    예) 0 ~ 9 까지의 손글씨 숫자 이미지를 구성한다면 결과 5일 때 원핫 인코딩
        [0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ,0]

[평가지표]
    1. accuracy : 분류 모델의 성능을 평가하는 지표 # 1에 가까울수록 좋은 성능

